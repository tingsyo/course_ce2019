{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topics in Cloud and Environment (2019)\n",
    "\n",
    "## Example: Feature Selection\n",
    "\n",
    "---\n",
    "\n",
    "The classes in the [`sklearn.feature_selection`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection) module can be used for feature selection/dimensionality reduction on sample sets, either to improve estimatorsâ€™ accuracy scores or to boost their performance on very high-dimensional datasets. For further details, please visit the [reference](https://scikit-learn.org/stable/modules/feature_selection.html).\n",
    "\n",
    "Take regression as example, feature selection can be done either forward or backward. The forward approach adds variables one-by-one, while the backward approach eliminate variables one by one.\n",
    "\n",
    "Here we are using the logistic regression as an example to work with a few feature selection methods.\n",
    "\n",
    "### Load data\n",
    "\n",
    "First, we use the 10-day sums of weather events as X, and the air-polution event as Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimension: \n",
      "(3652, 13)\n",
      "(3652,)\n",
      "Variables\n",
      "['CS', 'FT', 'NE', 'SNE', 'SWF', 'SSWF', 'TYW', 'TC100', 'TC200', 'TC300', 'TC500', 'TC1000', 'NWPTY']\n"
     ]
    }
   ],
   "source": [
    "# Load library\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# Load data\n",
    "y = pd.read_csv('../data/ap_events_2005-2014.csv',  index_col=0)\n",
    "x = pd.read_csv('../data/weather_event_10day_sums_2005-2014.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model tuning work flow\n",
    "\n",
    "Earlier, we introduced a model tuning work flow, and now we use this example to demonstrate how to do it.\n",
    "\n",
    "<img src='figures/grid_search_workflow.png' width='400px'/>\n",
    "\n",
    "As shown in the figure, we first split our dataset into training set and test set. The tuning of model, e.g., model selection and feature selection, are executed with the CV on the training set. After the tuning process, a final model is trained with the full training set and then test against the test set. Thus, we can see the effects of different model tuning techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data dimension: \n",
      "    Training set: \n",
      "(3287, 13)\n",
      "(3287,)\n",
      "    Test set: \n",
      "(365, 13)\n",
      "(365,)\n",
      "\n",
      "Variables:\n",
      "['CS', 'FT', 'NE', 'SNE', 'SWF', 'SSWF', 'TYW', 'TC100', 'TC200', 'TC300', 'TC500', 'TC1000', 'NWPTY']\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing: 2005~2013 for training, and 2014 for testing\n",
    "x_test = np.array(x.iloc[3287:,:])\n",
    "y_test = np.array(y.iloc[3287:,:]).flatten()\n",
    "X = np.array(x.iloc[:3287,:])\n",
    "Y = np.array(y.iloc[:3287,:]).flatten()\n",
    "#\n",
    "print('Data dimension: ')\n",
    "print('    Training set: ')\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print('    Test set: ')\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print()\n",
    "print('Variables:')\n",
    "print(list(x.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Logistic Regression\n",
    "\n",
    "Then, we use X to predict Y using logistic regression as shown in [earlier example](https://github.com/tingsyo/course_ce2019/blob/master/week04_generalized_linear_model/Generalized_Linear_Model.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction     0    1\n",
      "Truth                \n",
      "0           2271  183\n",
      "1            616  217\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85      2454\n",
      "           1       0.54      0.26      0.35       833\n",
      "\n",
      "    accuracy                           0.76      3287\n",
      "   macro avg       0.66      0.59      0.60      3287\n",
      "weighted avg       0.72      0.76      0.72      3287\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.439306\n",
      "         Iterations 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>y</td>        <th>  No. Observations:  </th>   <td>  3287</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  3274</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>    12</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 28 May 2019</td> <th>  Pseudo R-squ.:     </th>   <td>0.2239</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>11:43:02</td>     <th>  Log-Likelihood:    </th>  <td> -1444.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th>  <td> -1860.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.187e-170</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>      <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>  <td>   -0.0219</td> <td>    0.069</td> <td>   -0.317</td> <td> 0.751</td> <td>   -0.157</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>  <td>   -0.1436</td> <td>    0.025</td> <td>   -5.840</td> <td> 0.000</td> <td>   -0.192</td> <td>   -0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>  <td>    0.1382</td> <td>    0.032</td> <td>    4.284</td> <td> 0.000</td> <td>    0.075</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>  <td>   -0.1980</td> <td>    0.038</td> <td>   -5.181</td> <td> 0.000</td> <td>   -0.273</td> <td>   -0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>  <td>   -0.2811</td> <td>    0.045</td> <td>   -6.299</td> <td> 0.000</td> <td>   -0.369</td> <td>   -0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>  <td>   -0.4000</td> <td>    0.107</td> <td>   -3.721</td> <td> 0.000</td> <td>   -0.611</td> <td>   -0.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>  <td>    0.0790</td> <td>    0.151</td> <td>    0.522</td> <td> 0.602</td> <td>   -0.218</td> <td>    0.376</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>  <td>   -0.7937</td> <td>    0.311</td> <td>   -2.553</td> <td> 0.011</td> <td>   -1.403</td> <td>   -0.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>  <td>    0.7395</td> <td>    0.290</td> <td>    2.548</td> <td> 0.011</td> <td>    0.171</td> <td>    1.308</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th> <td>    0.3192</td> <td>    0.255</td> <td>    1.252</td> <td> 0.211</td> <td>   -0.181</td> <td>    0.819</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th> <td>    0.0701</td> <td>    0.155</td> <td>    0.453</td> <td> 0.651</td> <td>   -0.233</td> <td>    0.373</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th> <td>   -0.3851</td> <td>    0.051</td> <td>   -7.507</td> <td> 0.000</td> <td>   -0.486</td> <td>   -0.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th> <td>   -0.0103</td> <td>    0.015</td> <td>   -0.704</td> <td> 0.481</td> <td>   -0.039</td> <td>    0.018</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                 3287\n",
       "Model:                          Logit   Df Residuals:                     3274\n",
       "Method:                           MLE   Df Model:                           12\n",
       "Date:                Tue, 28 May 2019   Pseudo R-squ.:                  0.2239\n",
       "Time:                        11:43:02   Log-Likelihood:                -1444.0\n",
       "converged:                       True   LL-Null:                       -1860.7\n",
       "                                        LLR p-value:                1.187e-170\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.0219      0.069     -0.317      0.751      -0.157       0.113\n",
       "x2            -0.1436      0.025     -5.840      0.000      -0.192      -0.095\n",
       "x3             0.1382      0.032      4.284      0.000       0.075       0.201\n",
       "x4            -0.1980      0.038     -5.181      0.000      -0.273      -0.123\n",
       "x5            -0.2811      0.045     -6.299      0.000      -0.369      -0.194\n",
       "x6            -0.4000      0.107     -3.721      0.000      -0.611      -0.189\n",
       "x7             0.0790      0.151      0.522      0.602      -0.218       0.376\n",
       "x8            -0.7937      0.311     -2.553      0.011      -1.403      -0.184\n",
       "x9             0.7395      0.290      2.548      0.011       0.171       1.308\n",
       "x10            0.3192      0.255      1.252      0.211      -0.181       0.819\n",
       "x11            0.0701      0.155      0.453      0.651      -0.233       0.373\n",
       "x12           -0.3851      0.051     -7.507      0.000      -0.486      -0.285\n",
       "x13           -0.0103      0.015     -0.704      0.481      -0.039       0.018\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Fit the classifier\n",
    "glm = LogisticRegression(C=1e5, solver='lbfgs', max_iter=500)\n",
    "glm.fit(X, Y)\n",
    "\n",
    "# Metrics function for reuse\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    # Create confusion matrix\n",
    "    cfm = pd.crosstab(y_true, y_pred, rownames=['Truth'], colnames=['Prediction'])\n",
    "    # Create report\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "    cr = classification_report(y_true, y_pred)\n",
    "    return({'matrix':cfm, 'report':cr})\n",
    "\n",
    "# Show results on training set\n",
    "yhat_glm = glm.predict(X)\n",
    "cfm = evaluate_model(Y, yhat_glm)\n",
    "print(cfm['matrix'])\n",
    "print()\n",
    "print(cfm['report'])\n",
    "\n",
    "# Comprehensive evaluation\n",
    "glmsm = sm.Logit(Y, X)\n",
    "glmsm.fit(maxiter=30).summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(365,)\n",
      "(365,)\n",
      "Prediction    0   1\n",
      "Truth              \n",
      "0           285  43\n",
      "1            25  12\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89       328\n",
      "           1       0.22      0.32      0.26        37\n",
      "\n",
      "    accuracy                           0.81       365\n",
      "   macro avg       0.57      0.60      0.58       365\n",
      "weighted avg       0.85      0.81      0.83       365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show results on test set\n",
    "yp_glm = glm.predict(x_test)\n",
    "print(yp_glm.shape)\n",
    "print(y_test.shape)\n",
    "ev_glm_test = evaluate_model(y_test, yp_glm)\n",
    "print(ev_glm_test['matrix'])\n",
    "print()\n",
    "print(ev_glm_test['report'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selec features based on GLM summary\n",
    "\n",
    "Next, let's see if we select features based on it's p-value in the GLM summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3287, 8)\n",
      "Prediction     0    1\n",
      "Truth                \n",
      "0           2296  158\n",
      "1            649  184\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.94      0.85      2454\n",
      "           1       0.54      0.22      0.31       833\n",
      "\n",
      "    accuracy                           0.75      3287\n",
      "   macro avg       0.66      0.58      0.58      3287\n",
      "weighted avg       0.72      0.75      0.71      3287\n",
      "\n",
      "Prediction    0   1\n",
      "Truth              \n",
      "0           283  45\n",
      "1            28   9\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.89       328\n",
      "           1       0.17      0.24      0.20        37\n",
      "\n",
      "    accuracy                           0.80       365\n",
      "   macro avg       0.54      0.55      0.54       365\n",
      "weighted avg       0.83      0.80      0.82       365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pv05 = [1,2,3,4,5,7,8,11]\n",
    "x_pv = X[:, pv05]\n",
    "x_test_pv = x_test[:, pv05]\n",
    "print(x_pv.shape)\n",
    "# Fit the classifier\n",
    "glm = LogisticRegression(C=1e5, solver='lbfgs', max_iter=500)\n",
    "glm.fit(x_pv, Y)\n",
    "\n",
    "# Show results on training data\n",
    "yhat = glm.predict(x_pv)\n",
    "cfm = evaluate_model(Y, yhat)\n",
    "print(cfm['matrix'])\n",
    "print()\n",
    "print(cfm['report'])\n",
    "\n",
    "# Show results on test data\n",
    "yhat = glm.predict(x_test_pv)\n",
    "cfm = evaluate_model(y_test, yhat)\n",
    "print(cfm['matrix'])\n",
    "print()\n",
    "print(cfm['report'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate feature selection\n",
    "\n",
    "Univariate feature selection works by selecting the best features based on univariate statistical tests. It can be seen as a preprocessing step to an estimator. Scikit-learn exposes feature selection routines as objects that implement the `transform` method:\n",
    "\n",
    "- [`SelectKBest`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html) removes all but the $k$ highest scoring features\n",
    "- [`SelectPercentile`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html) removes all but a user-specified highest scoring percentage of features\n",
    "- using common univariate statistical tests for each feature: false positive rate [`SelectFpr`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFpr.html), false discovery rate [`SelectFdr`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFdr.html), or family wise error [`SelectFwe`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFwe.html).\n",
    "- [`GenericUnivariateSelect`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.GenericUnivariateSelect.html) allows to perform univariate feature selection with a configurable strategy. This allows to select the best univariate selection strategy with hyper-parameter search estimator.\n",
    "\n",
    "These objects take as input a scoring function that returns univariate scores and p-values:\n",
    "\n",
    "- For regression: [`f_regression`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html), [`mutual_info_regression`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html)\n",
    "- For classification: [`chi2`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html), [`f_classif`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html), [`mutual_info_classif`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html)\n",
    "\n",
    "The methods based on F-test estimate the degree of linear dependency between two random variables. On the other hand, mutual information methods can capture any kind of statistical dependency, but being nonparametric, they require more samples for accurate estimation.\n",
    "\n",
    "In the following example, we use [`mutual information`](https://en.wikipedia.org/wiki/Mutual_information) to select top 60% of features. Please feel free to use a different selection method or scores and compare the results with the full-feature model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3287, 8)\n",
      "Prediction     0    1\n",
      "Truth                \n",
      "0           2289  165\n",
      "1            652  181\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.93      0.85      2454\n",
      "           1       0.52      0.22      0.31       833\n",
      "\n",
      "    accuracy                           0.75      3287\n",
      "   macro avg       0.65      0.58      0.58      3287\n",
      "weighted avg       0.71      0.75      0.71      3287\n",
      "\n",
      "Prediction    0   1\n",
      "Truth              \n",
      "0           282  46\n",
      "1            28   9\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.88       328\n",
      "           1       0.16      0.24      0.20        37\n",
      "\n",
      "    accuracy                           0.80       365\n",
      "   macro avg       0.54      0.55      0.54       365\n",
      "weighted avg       0.83      0.80      0.81       365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
    "\n",
    "sp = SelectPercentile(mutual_info_classif, percentile=60)\n",
    "sp.fit(X, Y)\n",
    "newx = sp.transform(X)\n",
    "print(newx.shape)\n",
    "\n",
    "# Fit the classifier\n",
    "glm = LogisticRegression(C=1e5, solver='lbfgs', max_iter=500)\n",
    "glm.fit(newx, Y)\n",
    "yhat = glm.predict(newx)\n",
    "\n",
    "# Show results on training data\n",
    "cfm = evaluate_model(Y, yhat)\n",
    "print(cfm['matrix'])\n",
    "print()\n",
    "print(cfm['report'])\n",
    "\n",
    "# Show results on test data\n",
    "newx_test = sp.transform(x_test)\n",
    "yhat = glm.predict(newx_test)\n",
    "cfm = evaluate_model(y_test, yhat)\n",
    "print(cfm['matrix'])\n",
    "print()\n",
    "print(cfm['report'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive feature elimination with cross-validation\n",
    "\n",
    "A recursive feature elimination example with automatic tuning of the number of features selected with cross-validation. We need to specify a [`scoing metric`](https://scikit-learn.org/stable/modules/model_evaluation.html#model-evaluation) for the automatic selection process. Here we simply use *accuracy* of the classification as the criteria.\n",
    "\n",
    "- [note] This example took ~3 seconds on an Intel i7-7920H CPU with 16GB system memory, so please expect to wait for a few seconds, it's normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features : 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reference: https://scikit-learn.org/stable/auto_examples/feature_selection/plot_rfe_with_cross_validation.html\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# Create the RFE object and compute a cross-validated score.\n",
    "glm = LogisticRegression(C=1e5, solver='lbfgs', max_iter=500)\n",
    "# The \"accuracy\" scoring is proportional to the number of correct classifications\n",
    "rfecv = RFECV(estimator=glm, step=1, cv=StratifiedKFold(5), scoring='brier_score_loss')\n",
    "rfecv.fit(X, Y)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, RFE with 10-fold CV suggested that we use 4 features, which are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SWF', 'SSWF', 'TC100', 'TC200', 'TC300', 'TC1000']\n"
     ]
    }
   ],
   "source": [
    "x_sel = list(x.columns[rfecv.support_])\n",
    "print(x_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the GLM model summary, the choice of RFE does not match with the selection by *p-value*. So, let's see the perfromance of using these 4 features only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3287, 6)\n",
      "(365, 6)\n",
      "Prediction     0  1\n",
      "Truth              \n",
      "0           2450  4\n",
      "1            826  7\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86      2454\n",
      "           1       0.64      0.01      0.02       833\n",
      "\n",
      "    accuracy                           0.75      3287\n",
      "   macro avg       0.69      0.50      0.44      3287\n",
      "weighted avg       0.72      0.75      0.64      3287\n",
      "\n",
      "Prediction    0\n",
      "Truth          \n",
      "0           328\n",
      "1            37\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95       328\n",
      "           1       0.00      0.00      0.00        37\n",
      "\n",
      "    accuracy                           0.90       365\n",
      "   macro avg       0.45      0.50      0.47       365\n",
      "weighted avg       0.81      0.90      0.85       365\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\usr\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\usr\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\usr\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "x_rfe = np.array(x.loc[:,x_sel])[:3287,:]\n",
    "x_test_rfe = np.array(x.loc[:,x_sel])[3287:,:]\n",
    "print(x_rfe.shape)\n",
    "print(x_test_rfe.shape)\n",
    "# Fit the classifier\n",
    "glm = LogisticRegression(C=1e5, solver='lbfgs', max_iter=500)\n",
    "glm.fit(x_rfe, Y)\n",
    "yhat = glm.predict(x_rfe)\n",
    "\n",
    "# Show results on training set\n",
    "cfm = evaluate_model(Y, yhat)\n",
    "print(cfm['matrix'])\n",
    "print()\n",
    "print(cfm['report'])\n",
    "\n",
    "# Show results on test set\n",
    "yhat = glm.predict(x_test_rfe)\n",
    "cfm = evaluate_model(y_test, yhat)\n",
    "print(cfm['matrix'])\n",
    "print()\n",
    "print(cfm['report'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the example, the feature selection methods don't always work. This could be mainly caused by our choice of feature set (weather events) and model (logistic regression). We can achieve better results if we change our choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
